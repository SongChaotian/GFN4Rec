# ML1Mæ•°æ®æ ¼å¼å’Œåˆ’åˆ†è¯¦è§£ï¼ˆåŸºäºå®é™…ä»£ç éªŒè¯ç‰ˆï¼‰

## ğŸ“Œ å£°æ˜
æœ¬æ–‡æ¡£åŸºäºGFN4Recé¡¹ç›®çš„**å®é™…ä»£ç **åˆ†æï¼Œæ‰€æœ‰ç»“è®ºå‡æ¥è‡ªäºçœŸå®çš„ä»£ç å®ç°ï¼Œè€Œéæ¨æµ‹ã€‚

---

## 1. ç”¨æˆ·æ¨¡æ‹Ÿå™¨è®­ç»ƒçš„æ•°æ®æ ¼å¼

### 1.1 è®­ç»ƒé…ç½®

**è„šæœ¬**: `train_multi_behavior_user_response_movielens.sh`

```bash
python train_multibehavior.py\
    --reader MLSeqReader\                    # æ•°æ®è¯»å–å™¨
    --train_file ../dataset/ml1m/log_session.csv\
    --max_hist_seq_len 50\
    --val_holdout_per_user 5\                # éªŒè¯é›†: æ¯ç”¨æˆ·5ä¸ªäº¤äº’
    --test_holdout_per_user 5\               # æµ‹è¯•é›†: æ¯ç”¨æˆ·5ä¸ªäº¤äº’
    --model KRMBUserResponse_MaxOut\
    --batch_size 128
```

### 1.2 æ•°æ®åˆ’åˆ†æ–¹å¼

**æ¥è‡ª**: `reader/MLSeqReader.py`

```python
def _sequence_holdout(self, args):
    """
    æŒ‰ç”¨æˆ·æ—¶é—´åºåˆ—åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†
    """
    data = {"train": [], "val": [], "test": []}

    for u in tqdm(self.users):
        sub_df = self.log_data[self.log_data['user_id'] == u]
        n_train = len(sub_df) - args.val_holdout_per_user - args.test_holdout_per_user

        # è¿‡æ»¤æ‰è®­ç»ƒæ•°æ®è¿‡å°‘çš„ç”¨æˆ·ï¼ˆè®­ç»ƒé›†<60%æ€»æ•°æ®ï¼‰
        if n_train < 0.6 * len(sub_df):
            continue

        # æŒ‰æ—¶é—´é¡ºåºåˆ’åˆ†
        data['train'].append(list(sub_df.index[:n_train]))
        data['val'].append(list(sub_df.index[n_train:n_train+args.val_holdout_per_user]))
        data['test'].append(list(sub_df.index[-args.test_holdout_per_user:]))

    # åˆå¹¶æ‰€æœ‰ç”¨æˆ·çš„æ•°æ®
    for k, v in data.items():
        data[k] = np.concatenate(v)

    return data
```

**åˆ’åˆ†ç¤ºä¾‹**ï¼ˆå‡è®¾ç”¨æˆ·æœ‰100æ¡äº¤äº’ï¼‰:
```
ç”¨æˆ·1çš„äº¤äº’åºåˆ—ï¼ˆæŒ‰æ—¶é—´æ’åºï¼‰:
â”œâ”€ è®­ç»ƒé›†: index [0:90]    â†’ 90æ¡äº¤äº’ï¼ˆå‰90ä¸ªï¼‰
â”œâ”€ éªŒè¯é›†: index [90:95]   â†’ 5æ¡äº¤äº’ï¼ˆç¬¬91-95ä¸ªï¼‰
â””â”€ æµ‹è¯•é›†: index [95:100]  â†’ 5æ¡äº¤äº’ï¼ˆæœ€å5ä¸ªï¼‰

åˆå¹¶åçš„æ•°æ®æ ¼å¼ï¼š
data = {
    'train': [æ‰€æœ‰ç”¨æˆ·çš„è®­ç»ƒé›†è¡Œç´¢å¼•æ‹¼æ¥],
    'val': [æ‰€æœ‰ç”¨æˆ·çš„éªŒè¯é›†è¡Œç´¢å¼•æ‹¼æ¥],
    'test': [æ‰€æœ‰ç”¨æˆ·çš„æµ‹è¯•é›†è¡Œç´¢å¼•æ‹¼æ¥]
}
```

**å…³é”®ç‚¹**:
1. `val_holdout_per_user=5` å’Œ `test_holdout_per_user=5` æŒ‡çš„æ˜¯**äº¤äº’è®°å½•æ•°é‡**ï¼Œä¸æ˜¯slateæ•°é‡
2. æ•°æ®æŒ‰**å•ä¸ªäº¤äº’è®°å½•**ç»„ç»‡ï¼Œä¸æ¶‰åŠslateæ¦‚å¿µ
3. è¿”å›çš„æ˜¯è¡Œç´¢å¼•ï¼ˆrow indexï¼‰ï¼Œç”¨äºä»DataFrameä¸­æå–æ•°æ®

### 1.3 æ‰¹æ¬¡æ•°æ®æ ¼å¼

**æ¥è‡ª**: `reader/MLSeqReader.py`

```python
def __getitem__(self, idx):
    '''
    è¿”å›å•ä¸ªæ ·æœ¬:
    {
        'user_id': (1,)           # æ ‡é‡
        'item_id': (1,)           # æ ‡é‡
        'is_click': (1,)          # æ ‡é‡
        'is_like': (1,)           # æ ‡é‡
        'is_star': (1,)           # æ ‡é‡
        'uf_{feature}': (F_dim,)  # ç”¨æˆ·ç‰¹å¾å‘é‡
        'if_{feature}': (F_dim,)  # ç‰©å“ç‰¹å¾å‘é‡
        'history': (max_H,)       # å†å²ç‰©å“ID
        'history_length': (1,)    # æ ‡é‡
        'history_if_{feature}': (max_H, F_dim)
        'history_{response}': (max_H,)
    }
    '''
```

**DataLoader collateåçš„batch**:
```python
{
    'user_id': (B,)           # æ‰¹æ¬¡ä¸­çš„ç”¨æˆ·ID
    'item_id': (B,)           # æ‰¹æ¬¡ä¸­çš„ç‰©å“IDï¼ˆå•ä¸ªï¼‰
    'is_click': (B,)          # ç‚¹å‡»æ ‡ç­¾
    'is_like': (B,)           # ç‚¹èµæ ‡ç­¾
    'is_star': (B,)           # æ”¶è—æ ‡ç­¾
    'uf_gender': (B, 2),      # ç”¨æˆ·æ€§åˆ«ç‰¹å¾
    'uf_age': (B, 7),         # ç”¨æˆ·å¹´é¾„ç‰¹å¾
    'if_genres': (B, 18),     # ç‰©å“ç±»å‹ç‰¹å¾
    'history': (B, 50),       # ç”¨æˆ·å†å²
    'history_length': (B,),
    'history_if_genres': (B, 50, 18),
    'history_is_click': (B, 50),
    'history_is_like': (B, 50),
    'history_is_star': (B, 50),
}
```

**é‡è¦**: ç”¨æˆ·æ¨¡æ‹Ÿå™¨è®­ç»ƒæ—¶ï¼Œæ¯ä¸ªæ ·æœ¬æ˜¯**å•ä¸ªäº¤äº’è®°å½•**ï¼ˆä¸€ä¸ªç”¨æˆ·å¯¹ä¸€ä¸ªç‰©å“çš„åé¦ˆï¼‰ï¼Œä¸æ˜¯ä¸€ä¸ªslateã€‚

---

## 2. ç¦»çº¿è®­ç»ƒGFNçš„æ•°æ®æ ¼å¼

### 2.1 è®­ç»ƒé…ç½®

**è„šæœ¬**: `train_offline_gfn_db_movielens.sh`

```bash
python train_online_policy.py\
    --env_class MLUserEnvironment_ListRec\
    --slate_size 6\                          # â­ slateé•¿åº¦ä¸º6
    --new_reader_class MLSlateReader\        # â­ ä½¿ç”¨slateè¯»å–å™¨
    --env_test_holdout 1\                    # â­ æµ‹è¯•é›†holdout=1
    --policy_class SlateGFN_DB\
    --agent_class OfflineAgentWithOnlineTest\# â­ ç¦»çº¿è®­ç»ƒAgent
    --n_iter 10000\                          # 10000æ¬¡è¿­ä»£
    --batch_size 128
```

### 2.2 å…³é”®å·®å¼‚

| ç»´åº¦ | ç”¨æˆ·æ¨¡æ‹Ÿå™¨è®­ç»ƒ | ç¦»çº¿GFNè®­ç»ƒ |
|------|----------------|-------------|
| **æ•°æ®è¯»å–å™¨** | `MLSeqReader` | `MLSlateReader` |
| **slate_size** | æœªæŒ‡å®š | 6 |
| **æµ‹è¯•é›†** | æ¯ç”¨æˆ·5ä¸ªäº¤äº’ | æ¯ç”¨æˆ·1ä¸ªslateï¼ˆ6ä¸ªäº¤äº’ï¼‰|
| **Agent** | `KRMBUserResponse_MaxOut` | `OfflineAgentWithOnlineTest` |

### 2.3 æ•°æ®åˆ’åˆ†æ–¹å¼

**æ¥è‡ª**: `reader/MLSlateReader.py`

```python
class MLSlateReader(MLSeqReader):
    def __init__(self, args):
        self.slate_size = args.slate_size  # slate_size = 6
        super().__init__(args)
        
    def _sequence_holdout(self, args):
        data = {"train": [], "val": [], "test": []}
        
        for u in tqdm(self.users):
            sub_df = self.log_data[self.log_data['user_id'] == u]
            
            # â­ æ ¸å¿ƒï¼šè®¡ç®—è®­ç»ƒé›†å¤§å°ï¼ˆè€ƒè™‘slate_sizeï¼‰
            n_train = len(sub_df) - (args.val_holdout_per_user + args.test_holdout_per_user) * self.slate_size
            
            # â­ è®­ç»ƒé›†ï¼šæ¯éš”slate_sizeå–ä¸€ä¸ªèµ·å§‹ç´¢å¼•
            data['train'].append(list(sub_df.index[:n_train])[::self.slate_size])
            
            # éªŒè¯é›†ï¼šè¿ç»­çš„ val_holdout_per_user * slate_size ä¸ªäº¤äº’
            data['val'].append(list(sub_df.index[n_train:n_train+args.val_holdout_per_user*self.slate_size]))
            
            # â­ æµ‹è¯•é›†ï¼šæœ€å test_holdout_per_user * slate_size ä¸ªäº¤äº’ï¼Œæ¯éš”slate_sizeå–ä¸€ä¸ªèµ·å§‹ç´¢å¼•
            data['test'].append(list(sub_df.index[-args.test_holdout_per_user*self.slate_size::self.slate_size]))
        
        for k,v in data.items():
            data[k] = np.concatenate(v).astype(int)
        
        return data
```

**å‚æ•°å€¼**:
```bash
slate_size = 6
val_holdout_per_user = 0   # è„šæœ¬ä¸­æœªæŒ‡å®šï¼Œé»˜è®¤ä¸º0
test_holdout_per_user = 1  # é€šè¿‡ --env_test_holdout ä¼ é€’
```

**è®¡ç®—è¿‡ç¨‹**:
```python
# å‡è®¾ç”¨æˆ·æœ‰100æ¡äº¤äº’
n_train = 100 - (0 + 1) * 6 = 94

# è®­ç»ƒé›†ï¼šå‰94ä¸ªäº¤äº’ï¼Œæ¯éš”6ä¸ªå–ä¸€ä¸ªèµ·å§‹ç´¢å¼•
train_indices = [0, 6, 12, 18, 24, ..., 90]  # çº¦16ä¸ªslateèµ·å§‹ç‚¹

# éªŒè¯é›†ï¼šç©º
val_indices = []

# æµ‹è¯•é›†ï¼šæœ€å6ä¸ªäº¤äº’ï¼Œæ¯éš”6ä¸ªå–ä¸€ä¸ªèµ·å§‹ç´¢å¼•
test_indices = [94]  # 1ä¸ªslateèµ·å§‹ç‚¹
```

**åˆ’åˆ†ç¤ºä¾‹**ï¼ˆå‡è®¾ç”¨æˆ·æœ‰100æ¡äº¤äº’ï¼‰:
```
ç”¨æˆ·1çš„äº¤äº’åºåˆ—:
â”œâ”€ è®­ç»ƒé›†ç´¢å¼•: [0, 6, 12, 18, ..., 90]  â†’ 16ä¸ªslateèµ·å§‹ç‚¹
â”œâ”€ éªŒè¯é›†: []                           â†’ æ— 
â””â”€ æµ‹è¯•é›†ç´¢å¼•: [94]                     â†’ 1ä¸ªslateèµ·å§‹ç‚¹

æ¯ä¸ªç´¢å¼•ä»£è¡¨ä¸€ä¸ªslateçš„èµ·å§‹ä½ç½®:
- slate_0: äº¤äº’[0:6]
- slate_1: äº¤äº’[6:12]
- ...
- slate_15: äº¤äº’[90:96]
- slate_test: äº¤äº’[94:100]
```

**å…³é”®ç†è§£**:
1. `[::self.slate_size]` - Pythonåˆ‡ç‰‡è¯­æ³•ï¼Œè¡¨ç¤ºä»0å¼€å§‹ï¼Œæ¯éš”`slate_size`å–ä¸€ä¸ªå…ƒç´ 
2. è®­ç»ƒé›†å’Œæµ‹è¯•é›†åªå­˜å‚¨**slateçš„èµ·å§‹ç´¢å¼•**ï¼Œè€Œä¸æ˜¯æ‰€æœ‰äº¤äº’çš„ç´¢å¼•
3. éªŒè¯é›†å­˜å‚¨**è¿ç»­çš„ç´¢å¼•**ï¼ˆå¦‚æœä½¿ç”¨çš„è¯ï¼‰

### 2.4 æ‰¹æ¬¡æ•°æ®æ ¼å¼

**æ¥è‡ª**: `reader/MLSlateReader.py`

```python
def __getitem__(self, idx):
    '''
    è¿”å›å•ä¸ªslateæ ·æœ¬:
    {
        'user_id': (1,)
        'item_id': (slate_size,)           # slateä¸­çš„ç‰©å“åºåˆ—
        'is_click': (slate_size,)          # slateä¸­æ¯ä¸ªç‰©å“çš„ç‚¹å‡»
        'is_like': (slate_size,)
        'is_star': (slate_size,)
        'uf_{feature}': (F_dim,)
        'if_{feature}': (slate_size, F_dim)# slateä¸­æ¯ä¸ªç‰©å“çš„ç‰¹å¾
        'history': (max_H,)
        'history_length': (1,)
        'history_if_{feature}': (max_H, F_dim)
        'history_{response}': (max_H,)
    }
    '''
```

**DataLoader collateåçš„batch**:
```python
{
    'user_id': (B,)              # Bä¸ªç”¨æˆ·
    'item_id': (B, 6),           # Bä¸ªslateï¼Œæ¯ä¸ªåŒ…å«6ä¸ªç‰©å“
    'is_click': (B, 6),          # Bä¸ªslateçš„ç‚¹å‡»æ ‡ç­¾
    'is_like': (B, 6),
    'is_star': (B, 6),
    'uf_gender': (B, 2),
    'uf_age': (B, 7),
    'if_genres': (B, 6, 18),     # Bä¸ªslateä¸­æ¯ä¸ªç‰©å“çš„ç±»å‹ç‰¹å¾
    'history': (B, 50),
    'history_length': (B,),
    'history_if_genres': (B, 50, 18),
    'history_is_click': (B, 50),
    'history_is_like': (B, 50),
    'history_is_star': (B, 50),
}
```

**é‡è¦**: ç¦»çº¿GFNè®­ç»ƒæ—¶ï¼Œæ¯ä¸ªæ ·æœ¬æ˜¯**ä¸€ä¸ªslate**ï¼ˆä¸€ä¸ªç”¨æˆ·ä¸è¿ç»­6ä¸ªç‰©å“çš„äº¤äº’åºåˆ—ï¼‰ã€‚

### 2.5 è®­ç»ƒæ•°æ®ä½¿ç”¨

**ç¦»çº¿è®­ç»ƒæ—¶ä½¿ç”¨DataLoader**:
```python
# æ¥è‡ª OfflineAgentWithOnlineTest
def action_before_train(self):
    """åˆå§‹åŒ–DataLoader"""
    self.offline_iter = iter(DataLoader(
        self.env.reader,          # MLSlateReader
        batch_size=128,
        shuffle=True
    ))

def step_train(self):
    """ä»DataLoaderé‡‡æ ·å¹¶è®­ç»ƒ"""
    batch_sample = next(self.offline_iter)
    
    # æå–ç›‘ç£æ ‡ç­¾
    target_action = batch_sample['item_id'] - 1      # (B, 6)
    target_response = batch_sample[å“åº”ç±»å‹]         # (B, 6, 3)
    
    # GFNå‰å‘ä¼ æ’­ï¼ˆteacher forcingï¼‰
    policy_output = self.actor(
        observation, 
        action=target_action,      # ä½¿ç”¨ç¦»çº¿æ•°æ®çš„åŠ¨ä½œ
        response=target_response   # ä½¿ç”¨ç¦»çº¿æ•°æ®çš„åé¦ˆ
    )
    
    # è®¡ç®—GFNæŸå¤±ï¼ˆDBæŸå¤±ï¼‰
    loss = self.actor.get_loss(input_dict, policy_output)
    loss.backward()
```

---

## 3. åœ¨çº¿è®­ç»ƒGFNçš„æ•°æ®æ ¼å¼

### 3.1 è®­ç»ƒé…ç½®

**è„šæœ¬**: `train_gfn_db_movielens.sh`

```bash
python train_online_policy.py\
    --env_class MLUserEnvironment_ListRec\
    --slate_size 6\
    --agent_class BaseOnlineAgent\          # â­ åœ¨çº¿è®­ç»ƒAgent
    --n_iter 5000\                          # 5000æ¬¡è¿­ä»£
    --episode_batch_size 128\               # â­ æ¯æ¬¡äº¤äº’128ä¸ªç”¨æˆ·
    --batch_size 128\                       # â­ Bufferé‡‡æ ·128ä¸ªæ ·æœ¬
    --buffer_class SequentialBuffer\        # â­ ä½¿ç”¨Buffer
    --start_train_at_step 100\              # â­ å‰100æ­¥éšæœºæ¢ç´¢
    --initial_greedy_epsilon 0.05\          # â­ æ¢ç´¢ç‡0.05â†’0.01
    --final_greedy_epsilon 0.01
```

### 3.2 å…³é”®å·®å¼‚

| ç»´åº¦ | ç¦»çº¿GFNè®­ç»ƒ | åœ¨çº¿GFNè®­ç»ƒ |
|------|-------------|-------------|
| **Agent** | `OfflineAgentWithOnlineTest` | `BaseOnlineAgent` |
| **æ•°æ®æ¥æº** | DataLoaderï¼ˆç¦»çº¿æ—¥å¿—ï¼‰| ç¯å¢ƒå®æ—¶äº¤äº’ |
| **æ•°æ®è¯»å–å™¨** | `MLSlateReader` | ä¸éœ€è¦ |
| **è®­ç»ƒæ­¥æ•°** | 10000 steps | 5000 steps |
| **Buffer** | ä¸ä½¿ç”¨ | `SequentialBuffer`ï¼ˆ50000å®¹é‡ï¼‰|
| **æ¢ç´¢ç­–ç•¥** | æ—  | Îµ-greedyï¼ˆ0.05â†’0.01ï¼‰|

### 3.3 æ•°æ®æ¥æº

**åœ¨çº¿è®­ç»ƒä¸ä½¿ç”¨é™æ€æ•°æ®é›†**ï¼Œæ•°æ®æ¥æºäºï¼š

1. **ç¯å¢ƒé‡‡æ ·**: æ¯æ¬¡ä»ç”¨æˆ·é›†åˆä¸­éšæœºé‡‡æ ·128ä¸ªç”¨æˆ·
2. **ç­–ç•¥äº¤äº’**: ç­–ç•¥ä¸ºæ¯ä¸ªç”¨æˆ·ç”Ÿæˆæ¨èåˆ—è¡¨ï¼ˆslateï¼‰
3. **æ¨¡æ‹Ÿå™¨åé¦ˆ**: ç”¨æˆ·æ¨¡æ‹Ÿå™¨é¢„æµ‹ç”¨æˆ·å¯¹slateçš„åé¦ˆ
4. **Bufferå­˜å‚¨**: å°†äº¤äº’ç»éªŒï¼ˆs, a, r, s'ï¼‰å­˜å…¥Buffer
5. **Bufferé‡‡æ ·**: è®­ç»ƒæ—¶ä»Bufferä¸­é‡‡æ ·æ‰¹æ¬¡æ•°æ®

### 3.4 æ•°æ®æµ

**æ¥è‡ª**: `model/agent/BaseOnlineAgent.py`

```python
def action_before_train(self):
    """è®­ç»ƒå‰å‡†å¤‡ï¼šéšæœºæ¢ç´¢å¡«å……Buffer"""
    self.buffer.reset(self.env, self.actor)
    observation = self.env.reset()  # é‡‡æ ·128ä¸ªç”¨æˆ·
    
    for i in range(100):  # start_train_at_step=100
        observation = self.run_episode_step(
            0, 
            epsilon=1.0,  # å®Œå…¨éšæœºæ¢ç´¢
            observation, 
            do_buffer_update=True,  # å­˜å…¥Buffer
            do_explore=True
        )
    
    return observation

def train(self):
    """åœ¨çº¿è®­ç»ƒä¸»å¾ªç¯"""
    observation = self.action_before_train()
    
    for i in range(5000):  # N_ITER=5000
        epsilon = self.exploration_scheduler.value(i)  # 0.05â†’0.01
        
        # ã€æ ¸å¿ƒ1ã€‘ä¸ç¯å¢ƒäº¤äº’äº§ç”Ÿæ–°æ•°æ®
        observation = self.run_episode_step(
            i, epsilon, observation, 
            do_buffer_update=True,  # å­˜å…¥Buffer
            do_explore=True         # å¯ç”¨æ¢ç´¢
        )
        
        # ã€æ ¸å¿ƒ2ã€‘ä»Bufferé‡‡æ ·è®­ç»ƒ
        if i % 1 == 0:  # train_every_n_step=1
            self.step_train()

def run_episode_step(self, epsilon, observation, do_buffer_update, do_explore):
    """åœ¨çº¿äº¤äº’ä¸€æ­¥"""
    # 1. ç­–ç•¥ç”ŸæˆåŠ¨ä½œï¼ˆå¸¦Îµ-greedyæ¢ç´¢ï¼‰
    policy_output = self.actor({
        'observation': observation,
        'epsilon': epsilon,
        'do_explore': do_explore
    })
    # policy_output['action']: (128, 6)
    
    # 2. ç¯å¢ƒæ‰§è¡ŒåŠ¨ä½œï¼Œè·å–åé¦ˆ
    new_observation, user_feedback, updated_observation = \
        self.env.step({'action': policy_output['action']})
    # user_feedback['immediate_response']: (128, 6, 3)
    
    # 3. è®¡ç®—å¥–åŠ±
    R = self.reward_func(user_feedback)  # (128,)
    
    # 4. å­˜å…¥Buffer
    if do_buffer_update:
        self.buffer.update(
            observation,         # s_t
            policy_output,       # a_t, Ï€(a|s)
            user_feedback,       # r_t
            updated_observation  # s_{t+1}
        )
    
    return new_observation

def step_train(self):
    """ä»Bufferé‡‡æ ·å¹¶è®­ç»ƒ"""
    # ä»Bufferé‡‡æ ·128ä¸ªç»éªŒ
    observation, target_output, target_response, _, __ = \
        self.buffer.sample(128)
    
    # å‰å‘ä¼ æ’­
    policy_output = self.actor({
        'observation': observation,
        'action': target_output['action'],  # Bufferä¸­çš„åŠ¨ä½œ
        'response': target_response,        # Bufferä¸­çš„åé¦ˆ
        'is_train': True
    })
    
    # è®¡ç®—GFNæŸå¤±
    loss = self.actor.get_loss(input_dict, policy_output)
    loss.backward()
```

### 3.5 ç¯å¢ƒæ•°æ®æ ¼å¼

**ç¯å¢ƒé‡ç½®** (`env.reset()`):
```python
observation = {
    'user_id': (128,),              # 128ä¸ªéšæœºé‡‡æ ·çš„ç”¨æˆ·
    'uf_gender': (128, 2),
    'uf_age': (128, 7),
    'history': (128, 50),
    'history_length': (128,),
    'history_if_genres': (128, 50, 18),
    'history_is_click': (128, 50),
    'history_is_like': (128, 50),
    'history_is_star': (128, 50),
}
```

**ç¯å¢ƒäº¤äº’** (`env.step(action)`):
```python
# è¾“å…¥
action = (128, 6)  # 128ä¸ªç”¨æˆ·ï¼Œæ¯äºº6ä¸ªæ¨èç‰©å“

# è¾“å‡º
user_feedback = {
    'immediate_response': (128, 6, 3),  # 3ç§åé¦ˆï¼šclick, like, star
    'reward': (128,),                   # æ¯ä¸ªç”¨æˆ·çš„æ€»å¥–åŠ±
    'coverage': scalar,                 # è¦†ç›–ç‡
    'ILD': scalar,                      # åˆ—è¡¨å†…å¤šæ ·æ€§
}

new_observation = {...}  # æ›´æ–°åçš„ç”¨æˆ·çŠ¶æ€ï¼ˆæš‚ä¸æ›´æ–°ï¼Œè¿”å›åŸçŠ¶æ€ï¼‰
```

### 3.6 Bufferç»“æ„

**Bufferå­˜å‚¨çš„ç»éªŒ**:
```python
experience = {
    'observation': {
        'user_id': (128,),
        ...
    },
    'policy_output': {
        'action': (128, 6),      # é€‰æ‹©çš„ç‰©å“
        'prob': (128, 6),        # é€‰æ‹©æ¦‚ç‡
        'logF': (128, 7),        # DB: æµå€¼
    },
    'user_feedback': {
        'immediate_response': (128, 6, 3),
        'reward': (128,),
    },
    'next_observation': {...}
}

# Bufferå®¹é‡: 50000æ¡ç»éªŒ
# é‡‡æ ·: æ¯æ¬¡é‡‡æ ·128ä¸ªç»éªŒç”¨äºè®­ç»ƒ
```

---

## 4. ä¸‰ç§è®­ç»ƒæ–¹å¼çš„å®Œæ•´å¯¹æ¯”

### 4.1 é…ç½®å¯¹æ¯”è¡¨

| ç»´åº¦ | ç”¨æˆ·æ¨¡æ‹Ÿå™¨è®­ç»ƒ | ç¦»çº¿GFNè®­ç»ƒ | åœ¨çº¿GFNè®­ç»ƒ |
|------|----------------|-------------|-------------|
| **æ•°æ®è¯»å–å™¨** | `MLSeqReader` | `MLSlateReader` | ä¸éœ€è¦ |
| **æ•°æ®æ¥æº** | ç¦»çº¿æ—¥å¿—ï¼ˆæŒ‰äº¤äº’ï¼‰| ç¦»çº¿æ—¥å¿—ï¼ˆæŒ‰slateï¼‰| ç¯å¢ƒå®æ—¶äº¤äº’ |
| **slate_size** | æœªæŒ‡å®š | 6 | 6 |
| **æµ‹è¯•é›†** | æ¯ç”¨æˆ·5ä¸ªäº¤äº’ | æ¯ç”¨æˆ·1ä¸ªslateï¼ˆ6ä¸ªäº¤äº’ï¼‰| æœ€å100æ­¥ |
| **è®­ç»ƒæ–¹å¼** | ç›‘ç£å­¦ä¹ ï¼ˆBCEï¼‰| ç›‘ç£å­¦ä¹ ï¼ˆGFNï¼‰| å¼ºåŒ–å­¦ä¹ ï¼ˆGFNï¼‰|
| **è®­ç»ƒè¿­ä»£** | 10 epochs | 10000 steps | 5000 steps |
| **æ‰¹æ¬¡å¤§å°** | 128 | 128 | 128ï¼ˆBufferé‡‡æ ·ï¼‰|
| **episode_batch_size** | N/A | 128ï¼ˆä»…è¯„ä¼°ç”¨ï¼‰| 128ï¼ˆäº¤äº’ç”¨æˆ·æ•°ï¼‰|
| **æ¢ç´¢ç­–ç•¥** | æ—  | æ—  | Îµ-greedyï¼ˆ0.05â†’0.01ï¼‰|
| **Buffer** | ä¸ä½¿ç”¨ | ä¸ä½¿ç”¨ | 50000å®¹é‡ |
| **å†·å¯åŠ¨** | N/A | N/A | 100æ­¥éšæœºæ¢ç´¢ |

### 4.2 æ•°æ®æ ¼å¼å¯¹æ¯”

#### ç”¨æˆ·æ¨¡æ‹Ÿå™¨è®­ç»ƒçš„batch:
```python
{
    'user_id': (B,),
    'item_id': (B,),          # å•ä¸ªç‰©å“
    'is_click': (B,),         # å•ä¸ªæ ‡ç­¾
    'is_like': (B,),
    'is_star': (B,),
    ...
}
```

#### ç¦»çº¿GFNè®­ç»ƒçš„batch:
```python
{
    'user_id': (B,),
    'item_id': (B, 6),        # slateï¼ˆ6ä¸ªç‰©å“ï¼‰
    'is_click': (B, 6),       # slateçš„æ ‡ç­¾
    'is_like': (B, 6),
    'is_star': (B, 6),
    ...
}
```

#### åœ¨çº¿GFNè®­ç»ƒçš„batchï¼ˆä»Bufferé‡‡æ ·ï¼‰:
```python
{
    'observation': {
        'user_id': (B,),
        ...
    },
    'action': (B, 6),         # ç­–ç•¥ç”Ÿæˆçš„slate
    'immediate_response': (B, 6, 3),  # æ¨¡æ‹Ÿå™¨é¢„æµ‹çš„åé¦ˆ
    'reward': (B,),
    ...
}
```

---

## 5. å…³é”®ä»£ç ä½ç½®ç´¢å¼•

### 5.1 æ•°æ®è¯»å–å™¨
- `reader/MLSeqReader.py` - ç”¨æˆ·æ¨¡æ‹Ÿå™¨è®­ç»ƒçš„æ•°æ®è¯»å–
  - `_sequence_holdout()` - æ•°æ®åˆ’åˆ†é€»è¾‘ï¼ˆæŒ‰äº¤äº’ï¼‰
  - `__getitem__()` - è¿”å›å•ä¸ªäº¤äº’æ ·æœ¬
  
- `reader/MLSlateReader.py` - ç¦»çº¿GFNè®­ç»ƒçš„æ•°æ®è¯»å–
  - `_sequence_holdout()` - æ•°æ®åˆ’åˆ†é€»è¾‘ï¼ˆæŒ‰slateï¼‰
  - `__getitem__()` - è¿”å›å•ä¸ªslateæ ·æœ¬

### 5.2 è®­ç»ƒè„šæœ¬
- `train_multibehavior.py` - ç”¨æˆ·æ¨¡æ‹Ÿå™¨è®­ç»ƒä¸»ç¨‹åº
- `train_online_policy.py` - GFNè®­ç»ƒä¸»ç¨‹åºï¼ˆç¦»çº¿å’Œåœ¨çº¿å…±ç”¨ï¼‰

### 5.3 Agent
- `model/agent/OfflineAgentWithOnlineTest.py` - ç¦»çº¿GFNè®­ç»ƒ
  - `action_before_train()` - åˆå§‹åŒ–DataLoader
  - `step_train()` - ä»DataLoaderè®­ç»ƒ
  
- `model/agent/BaseOnlineAgent.py` - åœ¨çº¿GFNè®­ç»ƒ
  - `action_before_train()` - éšæœºæ¢ç´¢å¡«å……Buffer
  - `run_episode_step()` - åœ¨çº¿äº¤äº’
  - `step_train()` - ä»Bufferè®­ç»ƒ

---

## 6. è®ºæ–‡ä¸ä»£ç çš„å¯¹åº”

### 6.1 æ•°æ®åˆ’åˆ†

**è®ºæ–‡æè¿°**:
> "To engage in offline test, we split the last N interactions of each user's history as test samples while the remaining as training samples, and we set N = 1 for ML1M"

**ä»£ç å®ç°** (`reader/MLSlateReader.py`):
```python
# N = 1 æŒ‡çš„æ˜¯ 1ä¸ªslate
test_holdout_per_user = 1
slate_size = 6

# å› æ­¤æµ‹è¯•é›†æ˜¯æœ€å 1 * 6 = 6 ä¸ªäº¤äº’
n_train = len(sub_df) - 1 * 6

# æµ‹è¯•é›†ç´¢å¼•ï¼ˆæ¯éš”6ä¸ªå–ä¸€ä¸ªï¼Œåªå–1ä¸ªï¼‰
test_indices = list(sub_df.index[-6::6])  # åªæœ‰1ä¸ªç´¢å¼•
```

**ç»“è®º**: N=1 åœ¨ä»£ç ä¸­çš„å«ä¹‰æ˜¯**1ä¸ªslate**ï¼ˆ6ä¸ªè¿ç»­äº¤äº’ï¼‰ï¼Œè€Œä¸æ˜¯1ä¸ªäº¤äº’è®°å½•ã€‚

---

## æ€»ç»“

1. **ç”¨æˆ·æ¨¡æ‹Ÿå™¨è®­ç»ƒ**ï¼š
   - ä½¿ç”¨`MLSeqReader`æŒ‰**å•ä¸ªäº¤äº’è®°å½•**ç»„ç»‡æ•°æ®
   - æ¯ç”¨æˆ·ä¿ç•™æœ€å5ä¸ªäº¤äº’ä½œä¸ºéªŒè¯é›†å’Œæµ‹è¯•é›†
   - è®­ç»ƒç›®æ ‡ï¼šé¢„æµ‹å•ä¸ªç‰©å“çš„ç”¨æˆ·åé¦ˆ

2. **ç¦»çº¿GFNè®­ç»ƒ**ï¼š
   - ä½¿ç”¨`MLSlateReader`æŒ‰**slate**ç»„ç»‡æ•°æ®ï¼ˆslate_size=6ï¼‰
   - æ¯ç”¨æˆ·ä¿ç•™æœ€å1ä¸ªslateï¼ˆ6ä¸ªäº¤äº’ï¼‰ä½œä¸ºæµ‹è¯•é›†
   - ä½¿ç”¨DataLoaderä»ç¦»çº¿æ—¥å¿—ä¸­é‡‡æ ·
   - è®­ç»ƒç›®æ ‡ï¼šå­¦ä¹ ç”Ÿæˆé«˜è´¨é‡æ¨èåˆ—è¡¨

3. **åœ¨çº¿GFNè®­ç»ƒ**ï¼š
   - ä¸ä½¿ç”¨æ•°æ®è¯»å–å™¨ï¼Œé€šè¿‡ç¯å¢ƒå®æ—¶äº¤äº’äº§ç”Ÿæ•°æ®
   - æ¯æ¬¡äº¤äº’é‡‡æ ·128ä¸ªç”¨æˆ·ï¼Œç”Ÿæˆ128ä¸ªslate
   - ä½¿ç”¨Bufferå­˜å‚¨ç»éªŒï¼ˆå®¹é‡50000ï¼‰
   - é‡‡ç”¨Îµ-greedyç­–ç•¥æ¢ç´¢ï¼ˆ0.05â†’0.01ï¼‰
   - è®­ç»ƒç›®æ ‡ï¼šé€šè¿‡æ¢ç´¢å­¦ä¹ æœ€ä¼˜æ¨èç­–ç•¥

**æ ¸å¿ƒåŒºåˆ«**ï¼š
- ç”¨æˆ·æ¨¡æ‹Ÿå™¨ï¼šå•ä¸ªäº¤äº’ â†’ é¢„æµ‹åé¦ˆ
- ç¦»çº¿GFNï¼šç¦»çº¿slate â†’ ç›‘ç£å­¦ä¹ ç­–ç•¥
- åœ¨çº¿GFNï¼šåœ¨çº¿slate â†’ å¼ºåŒ–å­¦ä¹ ç­–ç•¥